<!DOCTYPE HTML>
<html lang="zh-tw" >
    <!-- Start book Scrapy框架 -->
<!-- Start book Scrapy框架 -->
    <head>
        <!-- head:start -->
<!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy模拟登陆 | Scrapy框架</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="gitbook/style.css">
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-maxiang/maxiang.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-emphasize/plugin.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="./09-scrapy_redis概念作用和流程.html" />
    
    
    <link rel="prev" href="./07-scrapy中间件的使用.html" />
    

        <!-- head:end -->
<!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
<!-- body:start -->
        
    <div class="book"
        data-level="8"
        data-chapter-title="scrapy模拟登陆"
        data-filepath="08-scrapy模拟登陆.md"
        data-basepath="."
        data-revision="Thu Sep 05 2019 11:12:18 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="./index.html">
                
                        <i class="fa fa-check"></i>
                        
                        联系方式
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="01-scrapy的概念作用和工作流程.html">
            
                
                    <a href="./01-scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2" data-path="02-scrapy的入门使用.html">
            
                
                    <a href="./02-scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3" data-path="03-scrapy入门案例/index.html">
            
                
                    <a href="./03-scrapy入门案例/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        scrapy入门案例：阳光工程
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="03-scrapy入门案例/阳光工程-1-下一页.html">
            
                
                    <a href="./03-scrapy入门案例/阳光工程-1-下一页.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        阳光工程-1-下一页
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="03-scrapy入门案例/阳光工程-2-合并数据.html">
            
                
                    <a href="./03-scrapy入门案例/阳光工程-2-合并数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        阳光工程-2-合并数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="03-scrapy入门案例/阳光工程-3-封装字典.html">
            
                
                    <a href="./03-scrapy入门案例/阳光工程-3-封装字典.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        阳光工程-3-封装字典
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="03-scrapy入门案例/阳光工程-4-总结.html">
            
                
                    <a href="./03-scrapy入门案例/阳光工程-4-总结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        总结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="04-crawlspider.html">
            
                
                    <a href="./04-crawlspider.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        crawlspider
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5" data-path="05-scrapy管道的使用.html">
            
                
                    <a href="./05-scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6" data-path="06-scrapy的debug、shell、配置.html">
            
                
                    <a href="./06-scrapy的debug、shell、配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        scrapy的debug、shell、配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7" data-path="07-scrapy中间件的使用.html">
            
                
                    <a href="./07-scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="8" data-path="08-scrapy模拟登陆.html">
            
                
                    <a href="./08-scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9" data-path="09-scrapy_redis概念作用和流程.html">
            
                
                    <a href="./09-scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10" data-path="10-研究scrapy-redis官方案例/index.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        研究scrapy-redis官方案例
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="10.1" data-path="10-研究scrapy-redis官方案例/01-下载scrapy-redis官方案例.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/01-下载scrapy-redis官方案例.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.1.</b>
                        
                        下载scrapy-redis官方案例
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="10-研究scrapy-redis官方案例/02-案例：dmoz.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/02-案例：dmoz.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.2.</b>
                        
                        案例：dmoz
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="10-研究scrapy-redis官方案例/03-案例：myspider_redis.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/03-案例：myspider_redis.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.3.</b>
                        
                        案例：myspider_redis
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="10-研究scrapy-redis官方案例/04-案例：mycrawler_redis.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/04-案例：mycrawler_redis.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.4.</b>
                        
                        案例：mycrawler_redis
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="10-研究scrapy-redis官方案例/05-总结.html">
            
                
                    <a href="./10-研究scrapy-redis官方案例/05-总结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.5.</b>
                        
                        总结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    本書使用 GitBook 釋出
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="./" >Scrapy框架</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="scrapy&#x6A21;&#x62DF;&#x767B;&#x9646;">scrapy&#x6A21;&#x62DF;&#x767B;&#x9646;</h1>
<h2 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;">&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;</h2>
<ol>
<li>&#x5E94;&#x7528; scrapy&#x76F4;&#x63A5;&#x643A;&#x5E26;cookie&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x5E94;&#x7528; scrapy.FormRequest()&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x8FDB;&#x884C;&#x767B;&#x9646;</li>
</ol>
<h2 id="1-&#x56DE;&#x987E;&#x4E4B;&#x524D;&#x7684;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x65B9;&#x6CD5;">1. &#x56DE;&#x987E;&#x4E4B;&#x524D;&#x7684;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x65B9;&#x6CD5;</h2>
<h3 id="11-requests&#x6A21;&#x5757;&#x662F;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;">1.1 requests&#x6A21;&#x5757;&#x662F;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;</h3>
<ol>
<li>&#x76F4;&#x63A5;&#x643A;&#x5E26;cookies&#x8BF7;&#x6C42;&#x9875;&#x9762;</li>
<li>&#x627E;url&#x5730;&#x5740;&#xFF0C;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x5B58;&#x50A8;cookie</li>
</ol>
<h3 id="12-selenium&#x662F;&#x5982;&#x4F55;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;">1.2 selenium&#x662F;&#x5982;&#x4F55;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;</h3>
<ol>
<li>&#x627E;&#x5230;&#x5BF9;&#x5E94;&#x7684;input&#x6807;&#x7B7E;&#xFF0C;&#x8F93;&#x5165;&#x6587;&#x672C;&#x70B9;&#x51FB;&#x767B;&#x9646;</li>
</ol>
<h3 id="13-scrapy&#x6709;&#x4E09;&#x79CD;&#x65B9;&#x6CD5;&#x6A21;&#x62DF;&#x767B;&#x9646;">1.3 scrapy&#x6709;&#x4E09;&#x79CD;&#x65B9;&#x6CD5;&#x6A21;&#x62DF;&#x767B;&#x9646;</h3>
<ol>
<li>&#x76F4;&#x63A5;&#x643A;&#x5E26;cookies</li>
<li>&#x627E;url&#x5730;&#x5740;&#xFF0C;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x5B58;&#x50A8;cookie</li>
<li>&#x627E;&#x5230;&#x5BF9;&#x5E94;&#x7684;form&#x8868;&#x5355;&#xFF0C;&#x81EA;&#x52A8;&#x89E3;&#x6790;input&#x6807;&#x7B7E;&#xFF0C;&#x81EA;&#x52A8;&#x89E3;&#x6790;post&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x81EA;&#x52A8;&#x5E26;&#x4E0A;&#x6570;&#x636E;&#xFF0C;&#x81EA;&#x52A8;&#x53D1;&#x9001;&#x8BF7;&#x6C42;</li>
</ol>
<h2 id="2-scrapy&#x643A;&#x5E26;cookies&#x76F4;&#x63A5;&#x83B7;&#x53D6;&#x9700;&#x8981;&#x767B;&#x9646;&#x540E;&#x7684;&#x9875;&#x9762;">2. scrapy&#x643A;&#x5E26;cookies&#x76F4;&#x63A5;&#x83B7;&#x53D6;&#x9700;&#x8981;&#x767B;&#x9646;&#x540E;&#x7684;&#x9875;&#x9762;</h2>
<h3 id="21-&#x5E94;&#x7528;&#x573A;&#x666F;">2.1 &#x5E94;&#x7528;&#x573A;&#x666F;</h3>
<ol>
<li>cookie&#x8FC7;&#x671F;&#x65F6;&#x95F4;&#x5F88;&#x957F;&#xFF0C;&#x5E38;&#x89C1;&#x4E8E;&#x4E00;&#x4E9B;&#x4E0D;&#x89C4;&#x8303;&#x7684;&#x7F51;&#x7AD9;</li>
<li>&#x80FD;&#x5728;cookie&#x8FC7;&#x671F;&#x4E4B;&#x524D;&#x628A;&#x641C;&#x6709;&#x7684;&#x6570;&#x636E;&#x62FF;&#x5230;</li>
<li>&#x914D;&#x5408;&#x5176;&#x4ED6;&#x7A0B;&#x5E8F;&#x4F7F;&#x7528;&#xFF0C;&#x6BD4;&#x5982;&#x5176;&#x4F7F;&#x7528;selenium&#x628A;&#x767B;&#x9646;&#x4E4B;&#x540E;&#x7684;cookie&#x83B7;&#x53D6;&#x5230;&#x4FDD;&#x5B58;&#x5230;&#x672C;&#x5730;&#xFF0C;scrapy&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x4E4B;&#x524D;&#x5148;&#x8BFB;&#x53D6;&#x672C;&#x5730;cookie</li>
</ol>
<h3 id="22-&#x5B9E;&#x73B0;&#xFF1A;&#x91CD;&#x6784;scrapy&#x7684;startrquests&#x65B9;&#x6CD5;">2.2 &#x5B9E;&#x73B0;&#xFF1A;&#x91CD;&#x6784;scrapy&#x7684;start_rquests&#x65B9;&#x6CD5;</h3>
<p>scrapy&#x4E2D;start_urls&#x662F;&#x901A;&#x8FC7;start_requests&#x6765;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x7684;&#xFF0C;&#x5176;&#x5B9E;&#x73B0;&#x4EE3;&#x7801;&#x5982;&#x4E0B;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
    cls = self.__class__
    <span class="hljs-keyword">if</span> method_is_overridden(cls, Spider, <span class="hljs-string">&apos;make_requests_from_url&apos;</span>):
        warnings.warn(
            <span class="hljs-string">&quot;Spider.make_requests_from_url method is deprecated; it &quot;</span>
            <span class="hljs-string">&quot;won&apos;t be called in future Scrapy releases. Please &quot;</span>
            <span class="hljs-string">&quot;override Spider.start_requests method instead (see %s.%s).&quot;</span> % (
                cls.__module__, cls.__name__
            ),
        )
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> self.start_urls:
            <span class="hljs-keyword">yield</span> self.make_requests_from_url(url)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> self.start_urls:
            <span class="hljs-keyword">yield</span> Request(url, dont_filter=<span class="hljs-keyword">True</span>)
</code></pre>
<p><strong>&#x6240;&#x4EE5;&#x5BF9;&#x5E94;&#x7684;&#xFF0C;&#x5982;&#x679C;start_urls&#x5730;&#x5740;&#x4E2D;&#x7684;url&#x662F;&#x9700;&#x8981;&#x767B;&#x5F55;&#x540E;&#x624D;&#x80FD;&#x8BBF;&#x95EE;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x91CD;&#x5199;start_request&#x65B9;&#x6CD5;&#x5E76;&#x5728;&#x5176;&#x4E2D;&#x624B;&#x52A8;&#x6DFB;&#x52A0;&#x4E0A;cookie</strong></p>
<h3 id="23-&#x643A;&#x5E26;cookies&#x767B;&#x9646;renren">2.3 &#x643A;&#x5E26;cookies&#x767B;&#x9646;renren</h3>
<pre><code class="lang-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ItSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;it&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;enren.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;http://www.renren.com/260246846/newsfeed/photo&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        print(<span class="hljs-string">&quot;----parse----&quot;</span>)
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">&quot;renren2.html&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:
            f.write(response.body.decode())

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>  <span class="hljs-comment"># &#x91CD;&#x6784;start_requests&#x65B9;&#x6CD5;</span>
        <span class="hljs-comment"># &#x8FD9;&#x4E2A;cookies_str&#x662F;&#x6293;&#x5305;&#x83B7;&#x53D6;&#x7684;</span>
        cookies_str = <span class="hljs-string">&quot;&quot;&quot;anonymid=jxkbmqz1k8rnj7; _r01_=1; depovince=GW; ick_login=bf826d1f-53dc-4829-81e1-da6554509e97; first_login_flag=1; ln_uact=dong4716138@163.com; ln_hurl=http://hdn.xnimg.cn/photos/hdn521/20190703/0820/main_Rdy3_c9750000c97b1986.jpg; JSESSIONID=abcHmX81Tn80iaLs-yHWw; jebecookies=210f9dee-e58e-4cb5-a3f8-777b74969dd9|||||; _de=55D1995656E8B7574112FD057B0CD36E34DF20B0B3AA6FF7; p=51eebfa2d9baf41144b0bc8858e9061b6; t=1d75b874aa18d7b78cf616e523078e0f6; societyguester=1d75b874aa18d7b78cf616e523078e0f6; id=260246846; xnsid=de931535; ver=7.0; loginfrom=null; wp_fold=0&quot;&quot;&quot;</span>  <span class="hljs-comment"># &#x6293;&#x5305;&#x83B7;&#x53D6;</span>
        <span class="hljs-comment"># &#x5C06;cookies_str&#x8F6C;&#x6362;&#x4E3A;cookies_dict</span>
        cookies_dict = {i[:i.find(<span class="hljs-string">&apos;=&apos;</span>)]: i[i.find(<span class="hljs-string">&apos;=&apos;</span>)+<span class="hljs-number">1</span>:] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> cookies_str.split(<span class="hljs-string">&apos;; &apos;</span>)}

        print(<span class="hljs-string">&quot;&gt;&gt;&gt;cookie&gt;&gt;&gt;&quot;</span>, cookies_dict)
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> self.start_urls:
            <span class="hljs-keyword">yield</span> scrapy.Request(
                url=url,
                callback=self.parse,
                cookies=cookies_dict
            )
</code></pre>
<h4 id="&#x6CE8;&#x610F;&#xFF1A;">&#x6CE8;&#x610F;&#xFF1A;</h4>
<ol>
<li>scrapy&#x4E2D;cookie&#x4E0D;&#x80FD;&#x591F;&#x653E;&#x5728;headers&#x4E2D;&#xFF0C;&#x5728;&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x7684;&#x65F6;&#x5019;&#x6709;&#x4E13;&#x95E8;&#x7684;cookies&#x53C2;&#x6570;&#xFF0C;&#x80FD;&#x591F;&#x63A5;&#x53D7;&#x5B57;&#x5178;&#x5F62;&#x5F0F;&#x7684;cookie</li>
<li>&#x5728;setting&#x4E2D;&#x8BBE;&#x7F6E;ROBOTS&#x534F;&#x8BAE;&#x3001;USER_AGENT</li>
</ol>
<h4 id="&#x6CE8;&#x610F;2&#xFF1A;">&#x6CE8;&#x610F;2&#xFF1A;</h4>
<p>&#x65E2;&#x7136;<code>start_urls</code>&#x5217;&#x8868;&#x4E2D;&#x7684;url&#x4F1A;&#x7ECF;&#x8FC7;<code>start_requests</code>&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x5982;&#x679C;&#x5728;<code>start_urls</code>&#x4E2D;&#x7684;url&#x9ED8;&#x8BA4;&#x9700;&#x8981;&#x7528;<code>POST</code>&#x63D0;&#x4EA4;&#x7684;&#x8BDD;&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x5728;<code>start_requests</code>&#x65B9;&#x6CD5;&#x4E2D;&#x8FDB;&#x884C;&#x5904;&#x7406; &#xFF0C;&#x5982;&#x4E0B;&#x56FE;</p>
<p><img src="assets/image-20190724092836557.png" alt="image-20190724092836557"></p>
<h2 id="3-scrapyformrequest&#x53D1;&#x9001;post&#x8BF7;&#x6C42;">3. scrapy.FormRequest&#x53D1;&#x9001;post&#x8BF7;&#x6C42;</h2>
<blockquote>
<p>&#x6211;&#x4EEC;&#x77E5;&#x9053;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;scrapy.Request()&#x6307;&#x5B9A;method&#x3001;body&#x53C2;&#x6570;&#x6765;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#xFF1B;&#x90A3;&#x4E48;&#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;scrapy.FormRequest()&#x6765;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;</p>
</blockquote>
<h3 id="31-scrapyformrequest&#x7684;&#x4F7F;&#x7528;">3.1 scrapy.FormRequest()&#x7684;&#x4F7F;&#x7528;</h3>
<p>&#x901A;&#x8FC7;scrapy.FormRequest&#x80FD;&#x591F;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#xFF0C;&#x540C;&#x65F6;&#x9700;&#x8981;&#x6DFB;&#x52A0;fromdata&#x53C2;&#x6570;&#x4F5C;&#x4E3A;&#x8BF7;&#x6C42;&#x4F53;&#xFF0C;&#x4EE5;&#x53CA;callback</p>
<pre><code class="lang-python"><span class="hljs-keyword">yield</span> scrapy.FormRequest(
    <span class="hljs-string">&quot;https://github.com/session&quot;</span>,
    formdata={
        <span class="hljs-string">&quot;authenticity_token&quot;</span>:authenticity_token,
        <span class="hljs-string">&quot;utf8&quot;</span>:utf8,
        <span class="hljs-string">&quot;commit&quot;</span>:commit,
        <span class="hljs-string">&quot;login&quot;</span>:<span class="hljs-string">&quot;dong4716138@163.com&quot;</span>,
        <span class="hljs-string">&quot;password&quot;</span>:<span class="hljs-string">&quot;xxxx&quot;</span>
    },
    callback=self.parse_login
)
</code></pre>
<h3 id="32-&#x4F7F;&#x7528;scrapyformrequest&#x767B;&#x9646;github">3.2 &#x4F7F;&#x7528;scrapy.FormRequest()&#x767B;&#x9646;github</h3>
<h4 id="321-&#x601D;&#x8DEF;&#x5206;&#x6790;">3.2.1 &#x601D;&#x8DEF;&#x5206;&#x6790;</h4>
<ol>
<li>&#x627E;&#x5230;post&#x7684;url&#x5730;&#x5740;&#xFF1A;&#x70B9;&#x51FB;&#x767B;&#x5F55;&#x6309;&#x94AE;&#x8FDB;&#x884C;&#x6293;&#x5305;&#xFF0C;&#x7136;&#x540E;&#x5B9A;&#x4F4D;url&#x5730;&#x5740;&#x4E3A;<a href="https://github.com/session" target="_blank">https://github.com/session</a></li>
<li>&#x627E;&#x5230;&#x8BF7;&#x6C42;&#x4F53;&#x7684;&#x89C4;&#x5F8B;&#xFF1A;&#x5206;&#x6790;post&#x8BF7;&#x6C42;&#x7684;&#x8BF7;&#x6C42;&#x4F53;&#xFF0C;&#x5176;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x53C2;&#x6570;&#x5747;&#x5728;&#x524D;&#x4E00;&#x6B21;&#x7684;&#x54CD;&#x5E94;&#x4E2D;</li>
<li>&#x5426;&#x767B;&#x5F55;&#x6210;&#x529F;&#xFF1A;&#x901A;&#x8FC7;&#x8BF7;&#x6C42;&#x4E2A;&#x4EBA;&#x4E3B;&#x9875;&#xFF0C;&#x89C2;&#x5BDF;&#x662F;&#x5426;&#x5305;&#x542B;&#x7528;&#x6237;&#x540D;</li>
</ol>
<h4 id="322-&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x5982;&#x4E0B;&#xFF1A;">3.2.2 &#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x5982;&#x4E0B;&#xFF1A;</h4>
<pre><code class="lang-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">import</span> re


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">GitSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;git&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;github.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;https://github.com/login&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        authenticity_token = response.xpath(<span class="hljs-string">&quot;//input[@name=&apos;authenticity_token&apos;]/@value&quot;</span>).extract_first()
        utf8 = response.xpath(<span class="hljs-string">&quot;//input[@name=&apos;utf8&apos;]/@value&quot;</span>).extract_first()
        commit = response.xpath(<span class="hljs-string">&quot;//input[@name=&apos;commit&apos;]/@value&quot;</span>).extract_first()

        <span class="hljs-comment"># &#x6784;&#x9020;POST&#x8BF7;&#x6C42;&#xFF0C;&#x4F20;&#x9012;&#x7ED9;&#x5F15;&#x64CE;</span>
        <span class="hljs-keyword">yield</span> scrapy.FormRequest(
            <span class="hljs-string">&quot;https://github.com/session&quot;</span>,
            formdata={
                <span class="hljs-string">&quot;authenticity_token&quot;</span>: authenticity_token,
                <span class="hljs-string">&quot;utf8&quot;</span>: utf8,
                <span class="hljs-string">&quot;commit&quot;</span>: commit,
                <span class="hljs-string">&quot;login&quot;</span>: <span class="hljs-string">&quot;993484988@qq.com&quot;</span>,  <span class="hljs-comment"># &#x586B;&#x5199;&#x81EA;&#x5DF1;&#x7684;GitHub&#x8D26;&#x53F7;</span>
                <span class="hljs-string">&quot;password&quot;</span>: <span class="hljs-string">&quot;xxxxxxx&quot;</span>,  <span class="hljs-comment"># &#x586B;&#x5199;&#x81EA;&#x5DF1;&#x7684;GitHub&#x5BC6;&#x7801;</span>
                <span class="hljs-string">&quot;webauthn - support&quot;</span>: <span class="hljs-string">&quot;supported&quot;</span>
            },
            callback=self.parse_login
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_login</span><span class="hljs-params">(self, response)</span>:</span>
        ret = re.findall(<span class="hljs-string">r&quot;dong138&quot;</span>, response.text)
        print(ret)
</code></pre>
<h2 id="4-&#x5C0F;&#x6280;&#x5DE7;">4. &#x5C0F;&#x6280;&#x5DE7;</h2>
<p>&#x5728;settings.py&#x4E2D;&#x901A;&#x8FC7;&#x8BBE;&#x7F6E;<code>COOKIES_DEBUG=True</code> &#x80FD;&#x591F;&#x5728;&#x7EC8;&#x7AEF;&#x770B;&#x5230;cookie&#x7684;&#x4F20;&#x9012;&#x4F20;&#x9012;&#x8FC7;&#x7A0B; </p>
<p><img src="assets/scrapy-login-1.png" alt="img"></p>
<h2 id="&#x603B;&#x7ED3;">&#x603B;&#x7ED3;</h2>
<ol>
<li>start_urls&#x4E2D;&#x7684;url&#x5730;&#x5740;&#x662F;&#x4EA4;&#x7ED9;start_request&#x5904;&#x7406;&#x7684;&#xFF0C;&#x5982;&#x6709;&#x5FC5;&#x8981;&#xFF0C;&#x53EF;&#x4EE5;&#x91CD;&#x5199;start_request&#x51FD;&#x6570;</li>
<li>&#x76F4;&#x63A5;&#x643A;&#x5E26;cookie&#x767B;&#x9646;&#xFF1A;cookie&#x53EA;&#x80FD;&#x4F20;&#x9012;&#x7ED9;cookies&#x53C2;&#x6570;&#x63A5;&#x6536;</li>
<li>scrapy.FormRequest()&#x53D1;&#x9001;post&#x8BF7;&#x6C42;</li>
</ol>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="./07-scrapy中间件的使用.html" class="navigation navigation-prev " aria-label="Previous page: scrapy中间件的使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="./09-scrapy_redis概念作用和流程.html" class="navigation navigation-next " aria-label="Next page: scrapy_redis概念作用和流程"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="gitbook/app.js"></script>

    
    <script src="gitbook/plugins/gitbook-plugin-maxiang/maxiang.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-book-summary-scroll-position-saver/book-summary-scroll-position-saver.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"maxiang":{},"toggle-chapters":{},"splitter":{},"emphasize":{},"book-summary-scroll-position-saver":{},"highlight":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
<!-- body:end -->
    </body>
    <!-- End of book Scrapy框架 -->
<!-- End of book Scrapy框架 -->
</html>
